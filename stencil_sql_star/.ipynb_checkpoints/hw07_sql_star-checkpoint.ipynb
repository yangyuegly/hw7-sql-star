{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7: Star Schemas and Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## SQL Database Design\n",
    "\n",
    "As mentioned in the [handout](https://docs.google.com/document/d/1bLgZ1cSOwai9DQ5o1BZDHt-s3mow5hhDLFVvnAb5k4M/edit#heading=h.u57jgzt5tmu8), Star Schemas are used commonly for data warehouses. Wikipedia has a short and clear [Star Schema](https://en.wikipedia.org/wiki/Star_schema) article.  This [reference](https://www.guru99.com/star-snowflake-data-warehousing.html) is also good, and describes both star schemas and their connection to snowflake schemas.\n",
    "\n",
    "In the first part of the assignment, you will develop a **star schema**.\n",
    "\n",
    "Tips:\n",
    "\n",
    "1. **Working with flat files/raw data**\n",
    "   When working with flat files of data it's important to check them out in their raw form (i.e. using a text editor or unix head command if the files are too big for your editor). For tabular data you should review every column and make sure you understand what it represents.  \n",
    "\n",
    "   For this assignment, we highly recommend you create a markdown cell with the name of every column that is currently in the file. (Copy and paste can be your friend here.)  Often times it you may need to fix the csv file before you import it. \n",
    "\n",
    "2. As you do this, sometimes there obvious poblems become apparent, such as header rows that need to skipped over (or deleted), and column names that are inappropriate for the system you are using. \n",
    "\n",
    "4. The file 'all_data_raw.csv' has two problems: extra lines at the beginning and inconsitent column names) that you should fix using the text editor. Column names should not contain spaces and should also be consistent.\n",
    "\n",
    "3. Create a new corrected version of the data file named 'all_data.csv'.\n",
    "\n",
    "Below is some code that will read an **appropiately** formated csv file and display its contents.  The strings in `all_data.csv` use the `latin1` character encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {},
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('all_data.csv', encoding='latin1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Draw a star schema for this dataset, save your drawing as an image and display it in the cell below.\n",
    "\n",
    "1. Your star schema should consist of one fact table and three dimension tables. \n",
    "1. For each table, underline the primary key.\n",
    "1. Specify data types for each item.\n",
    "1. Draw 1:N, N:1, N:N or 1:1 on connecting line.\n",
    "1. Including image in markdown is easy; see [here](https://stackoverflow.com/questions/255170/markdown-and-image-alignment).\n",
    "\n",
    "Your final drawing should be similar to this [Schema Drawing Example](https://docs.google.com/drawings/d/1Bd1l9LGJZnNQD6BTcZtLHsxWW1a3v07zuUYzz0TyZOk/edit?usp=sharing). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Solution***\n",
    "Insert your schema drawing here. (Save your drawing as my_movie_star_schema.jpg)\n",
    "\n",
    "![Movie Star Schema](my_movie_star_schema.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database Schema Creation\n",
    "\n",
    "In this part, you will create tables in a Postgres database to match your Star Schema design.\n",
    "\n",
    "The first thing ones need to do when interacting with a PostgreSQL database from python (and generally any SQL databases) is to open up a connection (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import csv\n",
    "\n",
    "# Create a connection to your hw7 database\n",
    "DSN = \"dbname='hw7' user='student' password=<your_password>\"\n",
    "conn = psycopg2.connect(DSN)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out connection by creating a table of \"parts\", where each part has a unique name\n",
    "cur.execute(\"\"\"\n",
    "DROP TABLE IF EXISTS parts;\n",
    "CREATE TABLE parts (\n",
    "    test_id SERIAL PRIMARY KEY,\n",
    "    name text,\n",
    "    price float,\n",
    "    UNIQUE (name));\n",
    "    \"\"\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try some inserts\n",
    "cur.execute(\"INSERT INTO parts (name, price) VALUES ('wheel', 10.00);\")\n",
    "\n",
    "# Warmup Exercise: \n",
    "# Start psql, and use `select * from parts`, and make note of when the inserts occur as you run this cell and the next two cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"INSERT INTO parts (name, price) VALUES ('cover', 3.00);\")\n",
    "\n",
    "# Warmup Exercise: \n",
    "# If you start from scratch (i.e., recreate an empty parts table) run the cell above\n",
    "# and this cell twice, what ends up in parts, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the test parts table\n",
    "cur.execute(\"\"\"DROP TABLE parts\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "# Warmup Exercise: \n",
    "# What happens if you run this cell more than once?  \n",
    "# Now try changing \"\"\"DROP TABLE parts\"\"\" to \"\"\"DROP TABLE IF EXISTS parts\"\"\" and try rerunning the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7.2 'create_database'\n",
    "Fill in function `create_database` with SQL commands do the following:\n",
    "\n",
    "- [DROP TABLE](https://www.postgresql.org/docs/8.2/sql-droptable.html) in the database. Doing this will allow you to to simply re-run `create_tables` if you want to try a new version of your schema.\n",
    "- [CREATE TABLE](https://www.postgresql.org/docs/current/sql-createtable.html) according to your star schema. This [Tutorial on Table Creation](https://www.postgresqltutorial.com/postgresql-python/create-tables/) will be helpful.\n",
    "\n",
    "You may assume the names of actors and directors uniquely identify them. Use the following datatypes: bugdget - BIGINT, imdb_score - float, aspect_ratio - float; the rest are text or int.  Define `PRIMARY KEY`s and `FOREIGN KEY`s in your tables where appropriate, \n",
    "refer to [here](https://www.postgresql.org/docs/9.2/ddl-constraints.html).\n",
    "\n",
    "\n",
    "**Tips:** \n",
    "- The [Tutorial on Table Creation](https://www.postgresqltutorial.com/postgresql-python/create-tables/) will help you write a list of appropriate drop and create table commands.\n",
    "- Many experienced programmers use the `psql` CLI or a tool like `pgAdmin` to develop SQL statements, and then **copy** them into the application program they are developing, with formatting as needed.\n",
    "- In PostgreSQL [`SERIAL PRIMARY KEY` column](https://chartio.com/resources/tutorials/how-to-define-an-auto-increment-primary-key-in-postgresql/)  is auto-incremented and is thus good for[IDs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "def create_tables(conn):\n",
    "    \"\"\" create tables in the PostgreSQL database\"\"\"\n",
    "    \n",
    "    #TODO: fill in DROP TABLE and CREATE TABLE statements as a sequence of\n",
    "    #strings in the variable named `commands`:\n",
    "\n",
    "    commands = (\n",
    "       )\n",
    "    \n",
    "    try:\n",
    "        # read the connection parameters\n",
    "        # connect to the PostgreSQL server\n",
    "        conn = psycopg2.connect(DSN)\n",
    "        cur = conn.cursor()\n",
    "        # create table one by one\n",
    "        for command in commands:\n",
    "            cur.execute(command)\n",
    "        # close communication with the PostgreSQL database server\n",
    "        cur.close()\n",
    "        # commit the changes\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(DSN)\n",
    "create_tables(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and Update\n",
    "\n",
    "Many database examples begin with different csv files, one for each table. \n",
    "However, this isn't how real world data is typically structured when you first receive it. \n",
    "\n",
    "Often, you will receive data \"dump\" files.  As a data scientist, you need to figure out how to do ETL to update this information into a live database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7.3: Database Update\n",
    "Fill in function update_database to insert the csv file contents into the movie database. \n",
    "\n",
    "1. Do not assume the database is empty.\n",
    "2. Inserting the exact same row a second time should not change the database.\n",
    "3. Work out the SQL statements need; do not use something like Pandas.DataFrame.to_sql().\n",
    "4. Make your solution independent of COLUMN ORDER in the input CSV.\n",
    "\n",
    "Tips:\n",
    "1. Use helper function to avoid redundant code\n",
    "2. You might working with a lists of column names helpful. \n",
    "3. In order to populate the fact table you will need to query the other tables to retrieve each dimension's row id. Here is some SQL code that does this that you are welcome to use:\n",
    "\n",
    "```sql\n",
    "        INSERT INTO facts \n",
    "        SELECT m.movie_id, d.director_id, a1.actor_id, a2.actor_id, a3.actor_id\n",
    "        FROM movies m, directors d, actors a1, actors a2, actors a3\n",
    "        WHERE m.movie_title = %(movie_title)s AND d.director_name = %(director_name)s AND a1.actor_name = %(actor_1_name)s \n",
    "        AND a2.actor_name = %(actor_2_name)s AND a3.actor_name = %(actor_3_name)s\n",
    "        ON CONFLICT DO NOTHING \n",
    "```\n",
    "4. Please wrap your execution statements in try except blocks as we did in create_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {},
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from sqlalchemy import text\n",
    "from psycopg2 import sql \n",
    "\n",
    "def update_database(conn, csv_file):\n",
    "    reader = csv.DictReader(open(csv_file, encoding='latin1'))\n",
    "    c = conn.cursor()\n",
    "    ###BEGIN SOLUTION: \n",
    "    #Your solution here\n",
    "    #insert into dimension tables\n",
    "    #insert into fact table\n",
    "    \n",
    "    \n",
    "    # for row in reader:\n",
    "        # iterate through every row in the csv file\n",
    "        # row contains a dictionary mapping column names to values\n",
    "        # row = {k: v.lower() for k, v in row.items()}\n",
    "    \n",
    "    ###END SOLUTION\n",
    "    conn.commit()\n",
    "    \n",
    "conn = psycopg2.connect(DSN)\n",
    "create_tables(conn)\n",
    "update_database(conn, 'all_data.csv')\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Task 7.4: Running Queries\n",
    "\n",
    "Now that you have created a database with the IMDB data. Your customer needs records that satisfy their requirements based on several constraints in order to improve their business revenue. \n",
    "In this part, you will create several SQL statements to extract them. \n",
    "\n",
    "IPython supports the use of the magic module called [%sql](https://pypi.python.org/pypi/ipython-sql) which allows us to easily interface with a database. To install, run the cell below; alternatively, during the setup steps for this homework you should have already installed it,  if not, you can\n",
    "run ```conda install -y -c conda-forge ipython-sql``` to install it now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following line will load this SQL extension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {},
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this command to connect the IPython shell to your database ```%sql postgresql://<postgres or your username>:<your password>@localhost:5432/<postgres or your database name>```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql postgresql://student:data1050!@localhost:5432/hw7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to write 10 queries that fetch certain records for your customers. To run SQL queries, first call <font color = \"red\">%%sql</font> magic and then write your SQL queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Query 7.4.1a: Find the number of directors in the directors table.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "%%sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Query 7.4.1b: Find the number of actors in the actors table.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "%%sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Query 7.4.1c: Find the number of movies in the movies table.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "%%sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There should be 1453 directors, 3872 actors, 3023 movies. Please make sure you get the same results before running the following queries.\n",
    "\n",
    "Now, we can have some fun querying the database!\n",
    "\n",
    "**Query 7.4.2: Find years that have more than 150 movies and arrange them in ascending order.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {},
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Query 7.4.3: Order director name from most Facebook likes to fewest Facebook likes and only show top 10 directors.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "%%sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Query 7.4.4: Return the titles of movies directed by Christopher Nolan ordered alphabetically.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "%%sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Query 7.4.5: Find all the directors who directed at least 5 movies since 2007 (included) sorted by the number of movies in descending order.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {},
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Query 7.4.6: Find the top five most productive actors since 2010 (included). \"Number of appearances\" is the most common metric choice but feel free to go with any of them. Include a short comment in the query to explain the metric you pick**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {},
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Query Optimization\n",
    "In this part, we will see how to optimize database access by indexing and using materialized views. \n",
    "\n",
    "The next three functions create and exercise a toy database.\n",
    "`setup_test` creates a connection to the database.  `insert_test` performs `num` SQL `SELECT`s, the  function `select_test` does `num` SQL `INSERT`s.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "def setup_test(conn):\n",
    "    c = conn.cursor()\n",
    "    c.execute('DROP TABLE IF EXISTS scripts CASCADE')\n",
    "    c.execute('''\n",
    "            CREATE TABLE scripts (\n",
    "                script_id SERIAL PRIMARY KEY,\n",
    "                author_name text,\n",
    "                script_name text\n",
    "                )\n",
    "                ''')\n",
    "    conn.commit()\n",
    "                \n",
    "\n",
    "def insert_test(conn, num):\n",
    "    c = conn.cursor()\n",
    "    for i in range(num):\n",
    "        c.execute('''INSERT INTO scripts (author_name, script_name) VALUES ('X', 'Magic %s')''',(i,))\n",
    "    conn.commit()\n",
    "\n",
    "def select_test(conn, num):\n",
    "    c = conn.cursor()\n",
    "    for i in range(num):\n",
    "        c.execute(\"SELECT * FROM scripts WHERE script_name = 'Magic %s' \",(i,))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is some code for benchmarking your database.  Run it to see how well your database currently performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(DSN)\n",
    "setup_test(conn)\n",
    "num_inserts = 15000\n",
    "num_selects = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 3 -r 3 insert_test(conn, num_inserts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT count(*) from scripts;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select pg_relation_size('scripts');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "%timeit -n 3 -r 3 select_test(conn, num_selects) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize the database so that `test_select` test performs more quickly by adding and INDEX.  Fill in the appropriate SQL commands in the cell below.  \n",
    "\n",
    "Hint: See [here](https://www.postgresql.org/docs/9.1/sql-createindex.html) for some information on  `INDEX` and `CREATE INDEX`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "setup_test(conn)\n",
    "c = conn.cursor()\n",
    "###BEGIN SOLUTION: \n",
    "#Your solution here\n",
    "#add index to the scripts relation\n",
    "\n",
    "\n",
    "###END SOLUTION\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to see how your optimization performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 3 -r 3 insert_test(conn, num_inserts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT count(*) from scripts;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select pg_relation_size('scripts');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "%timeit -n 3 -r 3 select_test(conn, num_selects) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7.5: Index trade-offs\n",
    "**Describe** and **explain** the performance changes you see when your index is added to the scripts table - what is the effect on the following:\n",
    " \n",
    "* insert speed\n",
    "* select speed\n",
    "* storage used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***BEGIN SOLUTION***\n",
    "\n",
    "Your answer here.\n",
    "\n",
    "***END SOLUTION***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7.6: Unique trade-offs (Optional: adds up to 20% to your homework score) \n",
    "Explore the UNIQUE constraint's impact on performance when applied to the script.script_name.  You'll probably need to create your own test setup.  At the end of your exploration, add a cell that summarizes your findings similar to way you did for the previous question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEGIN SOLUTION\n",
    "# Add cells here and below.\n",
    "### END SOLUTION"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
